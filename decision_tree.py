# -*- coding: utf-8 -*-
"""NBA Top 5 Players

Automatically generated by Colaboratory.

Assistance from https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/


Original file is located at
    https://colab.research.google.com/drive/1D_Wwojo4cxfLmMyFhgSGBIEdf7-lU0CH
"""

import pandas as pd
from google.colab import files
uploaded = files.upload()
import io
james = pd.read_csv(io.BytesIO(uploaded['James.csv']))
lebron = pd.read_csv(io.BytesIO(uploaded['LeBron.csv']))
giannis = pd.read_csv(io.BytesIO(uploaded['Giannis.csv']))
luka = pd.read_csv(io.BytesIO(uploaded['Luka.csv']))
damian = pd.read_csv(io.BytesIO(uploaded['Damian.csv']))

damian['Home'] = damian['Home'].fillna(1)
james['Home'] = james['Home'].fillna(1)
lebron['Home'] = lebron['Home'].fillna(1)
luka['Home'] = luka['Home'].fillna(1)
giannis['Home'] = giannis['Home'].fillna(1)

home = {1:1, '@': 0}
damian.Home = [home[item] for item in damian.Home] 
james.Home = [home[item] for item in james.Home] 
lebron.Home = [home[item] for item in lebron.Home] 
giannis.Home = [home[item] for item in giannis.Home] 
luka.Home = [home[item] for item in luka.Home]

luka.loc[luka['Outcome'].str.startswith("W"), 'Outcome'] = "1"
luka.loc[luka['Outcome'].str.startswith("L"), 'Outcome'] = "0"

damian.loc[damian['Outcome'].str.startswith("W"), 'Outcome'] = "1"
damian.loc[damian['Outcome'].str.startswith("L"), 'Outcome'] = "0"

giannis.loc[giannis['Outcome'].str.startswith("W"), 'Outcome'] = "1"
giannis.loc[giannis['Outcome'].str.startswith("L"), 'Outcome'] = "0"

lebron.loc[lebron['Outcome'].str.startswith("W"), 'Outcome'] = "1"
lebron.loc[lebron['Outcome'].str.startswith("L"), 'Outcome'] = "0"

james.loc[james['Outcome'].str.startswith("W"), 'Outcome'] = "1"
james.loc[james['Outcome'].str.startswith("L"), 'Outcome'] = "0"

outcome = {'1':1, '0': 0}
damian.Outcome = [outcome[item] for item in damian.Outcome] 
james.Outcome = [outcome[item] for item in james.Outcome] 
lebron.Outcome = [outcome[item] for item in lebron.Outcome] 
giannis.Outcome = [outcome[item] for item in giannis.Outcome] 
luka.Outcome = [outcome[item] for item in luka.Outcome]

damian.to_csv(r'C:\Users\twgeh\Documents\FALL20\Machine Learning\Final_Project\NBA_Top_5\All Cleaned Up\damian.csv', index = False)
james.to_csv(r'C:\Users\twgeh\Documents\FALL20\Machine Learning\Final_Project\NBA_Top_5\All Cleaned Up\james.csv', index = False)
lebron.to_csv(r'C:\Users\twgeh\Documents\FALL20\Machine Learning\Final_Project\NBA_Top_5\All Cleaned Up\lebron.csv', index = False)
giannis.to_csv(r'C:\Users\twgeh\Documents\FALL20\Machine Learning\Final_Project\NBA_Top_5\All Cleaned Up\giannis.csv', index = False)
luka.to_csv(r'C:\Users\twgeh\Documents\FALL20\Machine Learning\Final_Project\NBA_Top_5\All Cleaned Up\luka.csv', index = False)

luka['FT%'] = luka['FT%'].fillna(0)
lebron['FT%'] = lebron['FT%'].fillna(0)
james['FT%'] = james['FT%'].fillna(0)
damian['FT%'] = damian['FT%'].fillna(0)
giannis['FT%'] = giannis['FT%'].fillna(0)
luka['FG%'] = luka['FG%'].fillna(0)
lebron['FG%'] = lebron['FG%'].fillna(0)
james['FG%'] = james['FG%'].fillna(0)
damian['FG%'] = damian['FG%'].fillna(0)
giannis['FG%'] = giannis['FG%'].fillna(0)
luka['3P%'] = luka['3P%'].fillna(0)
lebron['3P%'] = lebron['3P%'].fillna(0)
james['3P%'] = james['3P%'].fillna(0)
damian['3P%'] = damian['3P%'].fillna(0)
giannis['3P%'] = giannis['3P%'].fillna(0)

giannis = giannis.drop(columns=['Diff', 'MP', '+/-'])
luka = luka.drop(columns=['Diff', 'MP', '+/-'])
lebron = lebron.drop(columns=['Diff', 'MP', '+/-'])
damian = damian.drop(columns=['Diff', 'MP', '+/-'])
james = james.drop(columns=['Diff', 'MP', '+/-'])

giannis = giannis[["Home", "FGA", "FG%", "3PA", "3P%", "FTA", "FT%", "ORB", "DRB", "TRB", "AST", "STL", "BLK", "TOV", "PF", "PTS", "GmSc", "Outcome"]]
luka = luka[["Home", "FGA", "FG%", "3PA", "3P%", "FTA", "FT%", "ORB", "DRB", "TRB", "AST", "STL", "BLK", "TOV", "PF", "PTS", "GmSc", "Outcome"]]
lebron = lebron[["Home", "FGA", "FG%", "3PA", "3P%", "FTA", "FT%", "ORB", "DRB", "TRB", "AST", "STL", "BLK", "TOV", "PF", "PTS", "GmSc", "Outcome"]]
damian = damian[["Home", "FGA", "FG%", "3PA", "3P%", "FTA", "FT%", "ORB", "DRB", "TRB", "AST", "STL", "BLK", "TOV", "PF", "PTS", "GmSc", "Outcome"]]
james = james[["Home", "FGA", "FG%", "3PA", "3P%", "FTA", "FT%", "ORB", "DRB", "TRB", "AST", "STL", "BLK", "TOV", "PF", "PTS", "GmSc", "Outcome"]]

giannis

from random import seed
from random import randrange

def fold_data(data, n_folds):
	folded_data = list()
	data = data.values.tolist() #this step just makes the dataframe a list for easier handling
	fold_size = int(len(data) / n_folds)
	for i in range(n_folds): #for each fold, grab the number of needed rows of data to put in each fold
		fold = list()
		while len(fold) < fold_size:
			index = randrange(len(data))
			fold.append(data.pop(index))
		folded_data.append(fold) #add these folds back in as a set of data, making folded_data a set of a set
	return folded_data

#calculate the accuracy of the prediction
def calculate_accuracy(actual, prediction):
	correct = 0
	for i in range(len(actual)):
		if actual[i] == prediction[i]:
			correct += 1
	return correct / len(prediction) * 100 #accuracy is just number correct out of the guesses

# Split the data set
def test_split(index, value, data):
	left, right = list(), list()
	for row in data:
		if row[index] < value:
			left.append(row)
		else:
			right.append(row)
	return left, right

#calculate the gini score
def gini(groups, classes):
	n_instances = float(sum([len(group) for group in groups]))
	gini_score = 0.0
	for group in groups:
		size = float(len(group))
		if size == 0:
			continue
		score = 0.0
		for class_val in classes:
			p = [row[-1] for row in group].count(class_val) / size
			score += p * p
		gini_score += (1.0 - score) * (size / n_instances)
	return gini_score


def split_point(data): #find the optimal split point using gini to calculate
	class_values = list(set(row[-1] for row in data))
	node_index = 10000
	node_value = 10000
	node_gini_score = 10000
	test_groups = None
	for index in range(len(data[0])-1):
		for row in data:
			groups = test_split(index, row[index], data) #the attribute points following the split test
			gini_val = gini(groups, class_values)
			if gini_val < node_gini_score: # Search for the best possible gini value at a given split
				node_index, node_value, node_gini_score, test_groups = index, row[index], gini_val, groups
	return {'index':node_index, 'value':node_value, 'groups':test_groups}

def make_end_node(group): #make the given node an endpoint
	outcomes = [row[-1] for row in group]
	return max(set(outcomes), key=outcomes.count)

#split the two nodes in two, standard splitting algorithm with end node classification
def split(node, max_depth, min_size, depth):
	left, right = node['groups']
	del(node['groups'])
	if not left or not right:
		node['left'] = node['right'] = make_end_node(left + right)
		return
	if depth >= max_depth:
		node['left'], node['right'] = make_end_node(left), make_end_node(right)
		return
	if len(left) <= min_size:
		node['left'] = make_end_node(left)
	else:
		node['left'] = split_point(left)
		split(node['left'], max_depth, min_size, depth+1)
	if len(right) <= min_size:
		node['right'] = make_end_node(right)
	else:
		node['right'] = split_point(right)
		split(node['right'], max_depth, min_size, depth+1)

def build_tree(train, max_depth, min_size): #make the tree based on the training data
	root = split_point(train)
	split(root, max_depth, min_size, 1)
	return root

#make a prediction by following the tree
def predict(node, row):
	if row[node['index']] < node['value']:
		if isinstance(node['left'], dict):
			return predict(node['left'], row)
		else:
			return node['left']
	else:
		if isinstance(node['right'], dict):
			return predict(node['right'], row)
		else:
			return node['right']

#Main function to return scores, predicted outcomes, and actual outcomes with any given data set
def DecisionTreeClassifier(data, n_folds, max_depth, min_size):
	folds = fold_data(data, n_folds)
	scores = list()
	for fold in folds:
		training = list(folds)
		training.remove(fold)
		training = sum(training, [])
		testing = list()
		for row in fold: #for a particular fold we want to predict the outcome
			row_copy = list(row) #to do this we copy the row over and then test our predictions
			testing.append(row_copy)
			row_copy[-1] = None
		predicted = decision_tree(training, testing, *args) #use the decision tree algorithm to predict data points for us
      tree = build_tree(training, max_depth, min_size)
	    predicted = list()
	    for row in testing:
		    prediction = predict(tree, row)
		    predicted.append(prediction)
      
		actual = [row[-1] for row in fold]
		accuracy = accuracy_metric(actual, predicted)
		scores.append(accuracy)
	return scores, predicted, actual


seed(0)
giannis_predicted = list()
giannis_actual = list()
giannis_scores, giannis_predicted, giannis_actual = DecisionTreeClassifier(giannis, 5, 5, 10)

lebron_predicted = list()
lebron_actual = list()
lebron_scores, lebron_predicted, lebron_actual = DecisionTreeClassifier(lebron, 5, 5, 10)

damian_predicted = list()
damian_actual = list()
damian_scores, damian_predicted, damian_actual = DecisionTreeClassifier(damian, 5, 5, 10)

james_predicted = list()
james_actual = list()
james_scores, james_predicted, james_actual = DecisionTreeClassifier(james, 5, 5, 10)

luka_predicted = list()
luka_actual = list()
luka_scores, luka_predicted, luka_actual = DecisionTreeClassifier(luka, 5, 5, 10)

seed(1)
giannis_scores2, giannis_predicted, giannis_actual = DecisionTreeClassifier(giannis, 5, 5, 10)
lebron_scores2, lebron_predicted, lebron_actual = DecisionTreeClassifier(lebron, 5, 5, 10)
damian_scores2, damian_predicted, damian_actual = DecisionTreeClassifier(damian, 5, 5, 10)
james_scores2, james_predicted, james_actual = DecisionTreeClassifier(james, 5, 5, 10)
luka_scores2, luka_predicted, luka_actual = DecisionTreeClassifier(luka, 5, 5, 10)

seed(2)
giannis_scores3, giannis_predicted, giannis_actual = DecisionTreeClassifier(giannis, 5, 5, 10)
lebron_scores3, lebron_predicted, lebron_actual = DecisionTreeClassifier(lebron, 5, 5, 10)
damian_scores3, damian_predicted, damian_actual = DecisionTreeClassifier(damian, 5, 5, 10)
james_scores3, james_predicted, james_actual = DecisionTreeClassifier(james, 5, 5, 10)
luka_scores3, luka_predicted, luka_actual = DecisionTreeClassifier(luka, 5, 5, 10)
seed(3)
giannis_scores4, giannis_predicted, giannis_actual = DecisionTreeClassifier(giannis, 5, 5, 10)
lebron_scores4, lebron_predicted, lebron_actual = DecisionTreeClassifier(lebron, 5, 5, 10)
damian_scores4, damian_predicted, damian_actual = DecisionTreeClassifier(damian, 5, 5, 10)
james_scores4, james_predicted, james_actual = DecisionTreeClassifier(james, 5, 5, 10)
luka_scores4, luka_predicted, luka_actual = DecisionTreeClassifier(luka, 5, 5, 10)

print('Giannis: %s' % (sum(giannis_scores+giannis_scores2+giannis_scores3+giannis_scores4)/20))
print('LeBron: %s' % (sum(lebron_scores+lebron_scores2+lebron_scores3+lebron_scores4)/20))
print('Harden: %s' % (sum(james_scores+james_scores2+james_scores3+james_scores4)/20))
print('Lillard: %s' % (sum(damian_scores+damian_scores2+damian_scores3+damian_scores4)/20))
print('Doncic: %s' % (sum(luka_scores+luka_scores2+luka_scores3+luka_scores4)/20))

plt.plot(luka_actual, c="blue", label="actual", marker='o', linestyle='none')
plt.plot(luka_predicted, c="red", label="predicted")
plt.xlabel("Games")
plt.ylabel("Game Outcome")
plt.title("Decision Tree Prediction for Luka Doncic")
plt.legend()

plt.axis([0, 10, -0.5, 1.5])
plt.yticks([0,1],['Loss', 'Win'])

plt.show()

plt.plot(james_actual, c="blue", label="actual", marker='o', linestyle='none')
plt.plot(james_predicted, c="red", label="predicted")
plt.xlabel("Games")
plt.ylabel("Game Outcome")
plt.title("Decision Tree Prediction for James Harden")
plt.legend()

plt.axis([0, 10, -0.5, 1.5])
plt.yticks([0,1],['Loss', 'Win'])

plt.show()

plt.plot(lebron_actual, c="blue", label="actual", marker='o', linestyle='none')
plt.plot(lebron_predicted, c="red", label="predicted")
plt.xlabel("Games")
plt.ylabel("Game Outcome")
plt.title("Decision Tree Prediction for LeBron James")
plt.legend()

plt.axis([0, 10, -0.5, 1.5])
plt.yticks([0,1],['Loss', 'Win'])

plt.show()

plt.plot(damian_actual, c="blue", label="actual", marker='o', linestyle='none')
plt.plot(damian_predicted, c="red", label="predicted")
plt.xlabel("Games")
plt.ylabel("Game Outcome")
plt.title("Decision Tree Prediction for Damian Lillard")
plt.legend()

plt.axis([0, 10, -0.5, 1.5])
plt.yticks([0,1],['Loss', 'Win'])

plt.show()

import matplotlib.pyplot as plt

plt.plot(actual, c="blue", label="actual", marker='o', linestyle='none')
plt.plot(predicted, c="red", label="predicted")
plt.xlabel("Games")
plt.ylabel("Game Outcome")
plt.title("Decision Tree Prediction for Giannis Antetokounmpo")
plt.legend()

plt.axis([0, 10, -0.5, 1.5])
plt.yticks([0,1],['Loss', 'Win'])

plt.show()

giannis
